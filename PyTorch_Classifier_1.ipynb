{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def import_training_labels():\n",
    "    labels = []\n",
    "    with open('train.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            labels.append(row[1])\n",
    "\n",
    "    labels.pop(0)\n",
    "\n",
    "    return labels\n",
    "\n",
    "label_list = [\"blues\", \"hiphop\", \"jazz\", \"metal\", \"disco\", \"country\", \"rock\", \"reggae\", \"classical\", \"pop\"]\n",
    "\n",
    "\n",
    "training_data = np.load(\"Training_Data_vector.npy\")\n",
    "\n",
    "means = np.mean(training_data, axis=1)\n",
    "means = means.reshape(len(means), 1)\n",
    "std_devs = np.std(training_data, axis=1)\n",
    "std_devs = std_devs.reshape(len(std_devs), 1)\n",
    "\n",
    "norm_training_data = (training_data - (means * np.ones((1, 700)))) / (std_devs * np.ones((1, 700)))\n",
    "tensor_train_data = torch.from_numpy(norm_training_data)\n",
    "\n",
    "\n",
    "training_labels = import_training_labels()\n",
    "le = preprocessing.LabelEncoder() # Changes text labels to numerical tensors\n",
    "le.fit(label_list)\n",
    "new_labels = le.transform(training_labels)\n",
    "tensor_labels = torch.tensor(new_labels)\n",
    "tensor_labels.resize(len(new_labels), 1) # TODO: fix this method so it's not the deprecated one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "entries_per_sample = 24\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(entries_per_sample, 256)\n",
    "        self.full_connect2 = nn.Linear(256, 128)\n",
    "        self.full_connect3 = nn.Linear(128, 64)\n",
    "        self.full_connect4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.full_connect1(x))\n",
    "        x = F.relu(self.full_connect2(x))\n",
    "        x = F.relu(self.full_connect3(x))\n",
    "        x = F.log_softmax(self.full_connect4(x), dim=0)\n",
    "#         x = self.full_connect4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(150):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0 #reset every epoch\n",
    "    for i in range(len(tensor_labels)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = tensor_train_data[:,i]\n",
    "        label = tensor_labels[i]\n",
    "        label = label.reshape((1,))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float()).reshape(1, 10)\n",
    "    \n",
    "        loss = criterion(outputs, label)\n",
    "#         loss = F.nll_loss(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    if epoch % 10 == 0:\n",
    "            print(f\"Finished epoch {epoch}, loss = {running_loss}\")\n",
    "\n",
    "print(f'Finished Training, final loss = {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TO EXPORT CURRENT MODEL\n",
    "PATH = './nn_classfier1.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TO LOAD SAVED MODEL\n",
    "net = Net()\n",
    "PATH = './nn_classifier1.pth'\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Training Data\n",
    "training_outputs = net(tensor_train_data.T.float())\n",
    "_, predicted_train = torch.max(training_outputs, 1)\n",
    "\n",
    "predicted_training_labels = le.inverse_transform(predicted_train)\n",
    "# print(predicted_training_labels)\n",
    "\n",
    "accuracy = torch.sum(predicted_train == tensor_labels)/700\n",
    "print(f\"Accuracy on Training Data: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test Data\n",
    "\n",
    "test_data_vector = np.load(\"Test_Data_vector.npy\")\n",
    "norm_test_data = (test_data_vector- (means * np.ones((1, 300)))) / (std_devs * np.ones((1, 300)))\n",
    "test_tensor = torch.from_numpy(norm_test_data)\n",
    "\n",
    "# print(test_tensor)\n",
    "outputs = net(test_tensor.T.float())\n",
    "# print(torch.max(net(tensor_train_data.T.float()), 1))\n",
    "# print(outputs)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "predicted_labels = le.inverse_transform(predicted)\n",
    "print(predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Test Data\n",
    "\n",
    "file_name = \"pytorch_classifier2\"\n",
    "\n",
    "with open(f'{file_name}.csv', 'w', newline='') as csvfile:\n",
    "    wrtr = csv.writer(csvfile, delimiter=',',\n",
    "                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    wrtr.writerow([\"filename\", \"label\"])\n",
    "    output_lists = [[f\"sample{i+700}.wav\", predicted_labels[i]] for i in range(300)]\n",
    "    wrtr.writerows(output_lists)\n",
    "print(f\"{file_name} exported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
